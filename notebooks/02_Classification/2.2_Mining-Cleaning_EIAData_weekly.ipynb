{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime\n",
    "from datetime import datetime as dt\n",
    "\n",
    "import re\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as soup\n",
    "\n",
    "import pyxlsb\n",
    "from pyxlsb import convert_date\n",
    "\n",
    "#%qtconsole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define local directories\n",
    "master_dir = 'C:\\\\Users\\\\Bryan\\\\OneDrive\\\\02 GitHub\\\\rig-count_L48\\\\'\n",
    "data_raw_dir = 'C:\\\\Users\\\\Bryan\\\\OneDrive\\\\02 GitHub\\\\rig-count_L48\\\\data\\\\raw\\\\'\n",
    "data_interim_dir = 'C:\\\\Users\\\\Bryan\\\\OneDrive\\\\02 GitHub\\\\rig-count_L48\\\\data\\\\interim\\\\'\n",
    "data_external_dir = 'C:\\\\Users\\\\Bryan\\\\OneDrive\\\\02 GitHub\\\\rig-count_L48\\\\data\\\\external\\\\'\n",
    "\n",
    "# Define eia API and URL\n",
    "api_key_eia = '231fd0a62041a63a05da2716cd3a73d6'\n",
    "url_eia = 'http://api.eia.gov/series/?api_key='+api_key_eia+'&out=json&series_id='"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Price and futures data.\n",
    "Available daily. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new data frame with wti_spot (DAILY)\n",
    "url_wti_spot = url_eia+'PET.RWTC.D'\n",
    "label = 'wti_spot'\n",
    "\n",
    "date_now = dt.now().date()\n",
    "\n",
    "# Get request from URL, convert to json\n",
    "r = requests.get(url_wti_spot)\n",
    "wti_spot_json = r.json()\n",
    "\n",
    "# Load json data and convert date to datetime\n",
    "df = pd.DataFrame(list(wti_spot_json['series'][0]['data']),columns=['date',label])\n",
    "df.date = pd.to_datetime(df.date, format='%Y-%m-%d')\n",
    "\n",
    "# Load data from time frame\n",
    "df = df[(df.date > '2009-11-15') & (df.date < str(dt.now().date()))]\n",
    "\n",
    "# Resample for weekly data - starting on Friday\n",
    "df = df.set_index('date').resample('W-FRI').mean()\n",
    "df = df.reset_index() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download brent_spot and merge with df (DAILY)\n",
    "url_trans = url_eia+'PET.RBRTE.D'\n",
    "label = 'brent_spot'\n",
    "\n",
    "# Get request from URL, convert to json\n",
    "r = requests.get(url_trans)\n",
    "json_trans = r.json()\n",
    "\n",
    "# Load json data and convert date to datetime\n",
    "df_eia_trans = pd.DataFrame(list(json_trans['series'][0]['data']),columns=['date',label])\n",
    "df_eia_trans.date = pd.to_datetime(df_eia_trans.date, format='%Y-%m-%d')\n",
    "\n",
    "# Load data from time frame\n",
    "df_eia_trans = df_eia_trans[(df_eia_trans.date > '2009-11-15') & (df_eia_trans.date < str(dt.now().date()))]\n",
    "\n",
    "# Resample for weekly data - starting on Friday\n",
    "df_eia_trans = df_eia_trans.set_index('date').resample('W-FRI').mean()\n",
    "df_eia_trans = df_eia_trans.reset_index()\n",
    "\n",
    "# Merge data frames\n",
    "df = df.merge(df_eia_trans, how='outer').sort_values('date', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download wti_fut_1 and merge with df (DAILY)\n",
    "url_trans = url_eia + 'PET.RCLC1.D'\n",
    "label = 'wti_fut_1'\n",
    "\n",
    "# Get request from URL, convert to json\n",
    "r = requests.get(url_trans)\n",
    "json_trans = r.json()\n",
    "\n",
    "# Load json data and convert date to datetime\n",
    "df_eia_trans = pd.DataFrame(list(json_trans['series'][0]['data']),columns=['date',label])\n",
    "df_eia_trans.date = pd.to_datetime(df_eia_trans.date, format='%Y-%m-%d')\n",
    "\n",
    "# Load data from time frame\n",
    "df_eia_trans = df_eia_trans[(df_eia_trans.date > '2009-11-15') & (df_eia_trans.date < str(dt.now().date()))]\n",
    "\n",
    "# Resample for weekly data - starting on Friday\n",
    "df_eia_trans = df_eia_trans.set_index('date').resample('W-FRI').mean()\n",
    "df_eia_trans = df_eia_trans.reset_index()\n",
    "\n",
    "# Merge data frames\n",
    "df = df.merge(df_eia_trans, how='outer').sort_values('date', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download wti_fut_2 and merge with df (DAILY)\n",
    "url_trans = url_eia + 'PET.RCLC2.D'\n",
    "label = 'wti_fut_2'\n",
    "\n",
    "# Get request from URL, convert to json\n",
    "r = requests.get(url_trans)\n",
    "json_trans = r.json()\n",
    "\n",
    "# Load json data and convert date to datetime\n",
    "df_eia_trans = pd.DataFrame(list(json_trans['series'][0]['data']),columns=['date',label])\n",
    "df_eia_trans.date = pd.to_datetime(df_eia_trans.date, format='%Y-%m-%d')\n",
    "\n",
    "# Load data from time frame\n",
    "df_eia_trans = df_eia_trans[(df_eia_trans.date > '2009-11-15') & (df_eia_trans.date < str(dt.now().date()))]\n",
    "\n",
    "# Resample for weekly data - starting on Friday\n",
    "df_eia_trans = df_eia_trans.set_index('date').resample('W-FRI').mean()\n",
    "df_eia_trans = df_eia_trans.reset_index()\n",
    "\n",
    "# Merge data frames\n",
    "df = df.merge(df_eia_trans, how='outer').sort_values('date', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download wti_fut_3 and merge with df (DAILY)\n",
    "url_trans = url_eia + 'PET.RCLC3.D'\n",
    "label = 'wti_fut_3'\n",
    "\n",
    "# Get request from URL, convert to json\n",
    "r = requests.get(url_trans)\n",
    "json_trans = r.json()\n",
    "\n",
    "# Load json data and convert date to datetime\n",
    "df_eia_trans = pd.DataFrame(list(json_trans['series'][0]['data']),columns=['date',label])\n",
    "df_eia_trans.date = pd.to_datetime(df_eia_trans.date, format='%Y-%m-%d')\n",
    "\n",
    "# Load data from time frame\n",
    "df_eia_trans = df_eia_trans[(df_eia_trans.date > '2009-11-15') & (df_eia_trans.date < str(dt.now().date()))]\n",
    "\n",
    "# Resample for weekly data - starting on Friday\n",
    "df_eia_trans = df_eia_trans.set_index('date').resample('W-FRI').mean()\n",
    "df_eia_trans = df_eia_trans.reset_index()\n",
    "\n",
    "# Merge data frames\n",
    "df = df.merge(df_eia_trans, how='outer').sort_values('date', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download wti_fut_4 and merge with df (DAILY)\n",
    "url_trans = url_eia + 'PET.RCLC4.D'\n",
    "label = 'wti_fut_4'\n",
    "\n",
    "# Get request from URL, convert to json\n",
    "r = requests.get(url_trans)\n",
    "json_trans = r.json()\n",
    "\n",
    "# Load json data and convert date to datetime\n",
    "df_eia_trans = pd.DataFrame(list(json_trans['series'][0]['data']),columns=['date',label])\n",
    "df_eia_trans.date = pd.to_datetime(df_eia_trans.date, format='%Y-%m-%d')\n",
    "\n",
    "# Load data from time frame\n",
    "df_eia_trans = df_eia_trans[(df_eia_trans.date > '2009-11-15') & (df_eia_trans.date < str(dt.now().date()))]\n",
    "\n",
    "# Resample for weekly data - starting on Friday\n",
    "df_eia_trans = df_eia_trans.set_index('date').resample('W-FRI').mean()\n",
    "df_eia_trans = df_eia_trans.reset_index()\n",
    "\n",
    "# Merge data frames\n",
    "df = df.merge(df_eia_trans, how='outer').sort_values('date', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USA import, storage,and production data.\n",
    "Available weekly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download usa_net_imp and merge with df (WEEKLY, kbpd)\n",
    "url_trans = url_eia + 'PET.WCRNTUS2.W'\n",
    "label = 'usa_net_import'\n",
    "\n",
    "# Get request from URL, convert to json\n",
    "r = requests.get(url_trans)\n",
    "json_trans = r.json()\n",
    "\n",
    "# Load json data and convert date to datetime\n",
    "df_eia_trans = pd.DataFrame(list(json_trans['series'][0]['data']),columns=['date',label])\n",
    "df_eia_trans.date = pd.to_datetime(df_eia_trans.date, format='%Y-%m-%d')\n",
    "\n",
    "# Load data from time frame\n",
    "df_eia_trans = df_eia_trans[(df_eia_trans.date > '2009-11-15') & (df_eia_trans.date < str(dt.now().date()))]\n",
    "\n",
    "# Convert units from kbpd to Mbpd\n",
    "df_eia_trans[label] = df_eia_trans[label].div(1000)\n",
    "\n",
    "# Merge data frames\n",
    "df = df.merge(df_eia_trans,how='outer').sort_values('date',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download usa_stocks_all and merge with df (WEEKLY, kb)\n",
    "url_trans = url_eia + 'PET.WCRSTUS1.W'\n",
    "label = 'usa_stocks_all'\n",
    "\n",
    "# Get request from URL, convert to json\n",
    "r = requests.get(url_trans)\n",
    "json_trans = r.json()\n",
    "\n",
    "# Load json data and convert date to datetime\n",
    "df_eia_trans = pd.DataFrame(list(json_trans['series'][0]['data']),columns=['date',label])\n",
    "df_eia_trans.date = pd.to_datetime(df_eia_trans.date, format='%Y-%m-%d')\n",
    "\n",
    "# Load data from time frame\n",
    "df_eia_trans = df_eia_trans[(df_eia_trans.date > '2009-11-15') & (df_eia_trans.date < str(dt.now().date()))]\n",
    "\n",
    "# Convert units from kb to Mb\n",
    "df_eia_trans[label] = df_eia_trans[label].div(1000)\n",
    "\n",
    "# Merge data frames\n",
    "df = df.merge(df_eia_trans,how='outer').sort_values('date',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download usa_stocks_spr and merge with df (WEEKLY, kb)\n",
    "url_trans = url_eia + 'PET.WCSSTUS1.W'\n",
    "label = 'usa_stocks_spr'\n",
    "\n",
    "# Get request from URL, convert to json\n",
    "r = requests.get(url_trans)\n",
    "json_trans = r.json()\n",
    "\n",
    "# Load json data and convert date to datetime\n",
    "df_eia_trans = pd.DataFrame(list(json_trans['series'][0]['data']),columns=['date',label])\n",
    "df_eia_trans.date = pd.to_datetime(df_eia_trans.date, format='%Y-%m-%d')\n",
    "\n",
    "# Load data from time frame\n",
    "df_eia_trans = df_eia_trans[(df_eia_trans.date > '2009-11-15') & (df_eia_trans.date < str(dt.now().date()))]\n",
    "\n",
    "# Convert units from kb to Mb\n",
    "df_eia_trans[label] = df_eia_trans[label].div(1000)\n",
    "\n",
    "# Merge data frames\n",
    "df = df.merge(df_eia_trans,how='outer').sort_values('date',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download usa_prod and merge with df (WEEKLY kbpd)\n",
    "url_trans = url_eia + 'PET.W_EPC0_FPF_R48_MBBLD.W'\n",
    "label = 'usa_l48_prod'\n",
    "\n",
    "# Get request from URL, convert to json\n",
    "r = requests.get(url_trans)\n",
    "json_trans = r.json()\n",
    "\n",
    "# Load json data and convert date to datetime\n",
    "df_eia_trans = pd.DataFrame(list(json_trans['series'][0]['data']),columns=['date',label])\n",
    "df_eia_trans.date = pd.to_datetime(df_eia_trans.date, format='%Y-%m-%d')\n",
    "\n",
    "# Load data from time frame\n",
    "df_eia_trans = df_eia_trans[(df_eia_trans.date > '2009-11-15') & (df_eia_trans.date < str(dt.now().date()))]\n",
    "\n",
    "# Convert units from kbpd to Mbpd\n",
    "df_eia_trans[label] = df_eia_trans[label].div(1000)\n",
    "\n",
    "# Merge data frames\n",
    "df = df.merge(df_eia_trans,how='outer').sort_values('date',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### International & OPEC production, consumption data.\n",
    "Available **monthly** only. \n",
    "\n",
    "Major assumption that the change is linear between months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download opec_tot_prod and merge with df (MONTHLY, Mbpd)\n",
    "url_trans = url_eia + 'STEO.PAPR_OPEC.M'\n",
    "label = 'opec_tot_prod'\n",
    "\n",
    "# Get request from URL, convert to json\n",
    "r = requests.get(url_trans)\n",
    "json_trans = r.json()\n",
    "\n",
    "# Load json data and convert date to YYYY-MM-DD, then to datetime\n",
    "df_eia_trans = pd.DataFrame(list(json_trans['series'][0]['data']),columns=['date',label])\n",
    "df_eia_trans.date = df_eia_trans.date + '01'\n",
    "df_eia_trans.date = pd.to_datetime(df_eia_trans.date, format='%Y-%m')\n",
    "\n",
    "# Load data from time frame\n",
    "df_eia_trans = df_eia_trans[(df_eia_trans.date > '2009-11-15') & (df_eia_trans.date < str(dt.now().date()))]\n",
    "\n",
    "# Resample for weekly data - starting on Friday\n",
    "df_eia_trans = df_eia_trans.set_index('date').resample('D').interpolate().asfreq('W-FRI')\n",
    "df_eia_trans = df_eia_trans.reset_index()\n",
    "\n",
    "# Merge data frames\n",
    "df = df.merge(df_eia_trans,how='outer').sort_values('date',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download opec_crud_prod and merge with df (MONTHLY, Mbpd)\n",
    "url_trans = url_eia + 'STEO.COPR_OPEC.M'\n",
    "label = 'opec_crud_prod'\n",
    "\n",
    "# Get request from URL, convert to json\n",
    "r = requests.get(url_trans)\n",
    "json_trans = r.json()\n",
    "\n",
    "# Load json data and convert date to YYYY-MM-DD, then to datetime\n",
    "df_eia_trans = pd.DataFrame(list(json_trans['series'][0]['data']),columns=['date',label])\n",
    "df_eia_trans.date = df_eia_trans.date + '01'\n",
    "df_eia_trans.date = pd.to_datetime(df_eia_trans.date, format='%Y-%m')\n",
    "\n",
    "# Load data from time frame\n",
    "df_eia_trans = df_eia_trans[(df_eia_trans.date > '2009-11-15') & (df_eia_trans.date < str(dt.now().date()))]\n",
    "\n",
    "# Resample for weekly data - starting on Friday\n",
    "df_eia_trans = df_eia_trans.set_index('date').resample('D').interpolate().asfreq('W-FRI')\n",
    "#df_eia_trans = df_eia_trans.reset_index()\n",
    "\n",
    "# Merge data frames\n",
    "#df = df.merge(df_eia_trans,how='outer').sort_values('date',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download opec_crud_capac and merge with df (MONTHLY, Mbpd)\n",
    "url_trans = url_eia + 'STEO.COPC_OPEC.M'\n",
    "label = 'opec_crud_capac'\n",
    "\n",
    "# Get request from URL, convert to json\n",
    "r = requests.get(url_trans)\n",
    "json_trans = r.json()\n",
    "\n",
    "# Load json data and convert date to YYYY-MM-DD, then to datetime\n",
    "df_eia_trans = pd.DataFrame(list(json_trans['series'][0]['data']),columns=['date',label])\n",
    "df_eia_trans.date = df_eia_trans.date + '01'\n",
    "df_eia_trans.date = pd.to_datetime(df_eia_trans.date, format='%Y-%m')\n",
    "\n",
    "# Load data from time frame\n",
    "df_eia_trans = df_eia_trans[(df_eia_trans.date > '2009-11-15') & (df_eia_trans.date < str(dt.now().date()))]\n",
    "\n",
    "# Resample for weekly data - starting on Friday\n",
    "df_eia_trans = df_eia_trans.set_index('date').resample('D').interpolate().asfreq('W-FRI')\n",
    "df_eia_trans = df_eia_trans.reset_index()\n",
    "\n",
    "# Merge data frames\n",
    "df = df.merge(df_eia_trans,how='outer').sort_values('date',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download opec_surp_capac and merge with df (MONTHLY, Mbpd)\n",
    "url_trans = url_eia + 'STEO.COPS_OPEC.M'\n",
    "label = 'opec_surp_capac'\n",
    "\n",
    "# Get request from URL, convert to json\n",
    "r = requests.get(url_trans)\n",
    "json_trans = r.json()\n",
    "\n",
    "# Load json data and convert date to YYYY-MM-DD, then to datetime\n",
    "df_eia_trans = pd.DataFrame(list(json_trans['series'][0]['data']),columns=['date',label])\n",
    "df_eia_trans.date = df_eia_trans.date + '01'\n",
    "df_eia_trans.date = pd.to_datetime(df_eia_trans.date, format='%Y-%m')\n",
    "\n",
    "# Load data from time frame\n",
    "df_eia_trans = df_eia_trans[(df_eia_trans.date > '2009-11-15') & (df_eia_trans.date < str(dt.now().date()))]\n",
    "\n",
    "# Resample for weekly data - starting on Friday\n",
    "df_eia_trans = df_eia_trans.set_index('date').resample('D').interpolate().asfreq('W-FRI')\n",
    "df_eia_trans = df_eia_trans.reset_index()\n",
    "\n",
    "# Merge data frames\n",
    "df = df.merge(df_eia_trans,how='outer').sort_values('date',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download non-opec_tot_prod and merge with df (MONTHLY)\n",
    "url_trans = url_eia + 'STEO.PAPR_NONOPEC.M'\n",
    "label = 'non-opec_tot_prod'\n",
    "\n",
    "# Get request from URL, convert to json\n",
    "r = requests.get(url_trans)\n",
    "json_trans = r.json()\n",
    "\n",
    "# Load json data and convert date to YYYY-MM-DD, then to datetime\n",
    "df_eia_trans = pd.DataFrame(list(json_trans['series'][0]['data']),columns=['date',label])\n",
    "df_eia_trans.date = df_eia_trans.date + '01'\n",
    "df_eia_trans.date = pd.to_datetime(df_eia_trans.date, format='%Y-%m')\n",
    "\n",
    "# Load data from time frame\n",
    "df_eia_trans = df_eia_trans[(df_eia_trans.date > '2009-11-15') & (df_eia_trans.date < str(dt.now().date()))]\n",
    "\n",
    "# Resample for weekly data - starting on Friday\n",
    "df_eia_trans = df_eia_trans.set_index('date').resample('D').interpolate().asfreq('W-FRI')\n",
    "df_eia_trans = df_eia_trans.reset_index()\n",
    "\n",
    "# Merge data frames\n",
    "df = df.merge(df_eia_trans,how='outer').sort_values('date',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download oecd_cons and merge with df (MONTHLY)\n",
    "url_trans = url_eia + 'STEO.PATC_OECD.M'\n",
    "label = 'oecd_cons'\n",
    "\n",
    "# Get request from URL, convert to json\n",
    "r = requests.get(url_trans)\n",
    "json_trans = r.json()\n",
    "\n",
    "# Load json data and convert date to YYYY-MM-DD, then to datetime\n",
    "df_eia_trans = pd.DataFrame(list(json_trans['series'][0]['data']),columns=['date',label])\n",
    "df_eia_trans.date = df_eia_trans.date + '01'\n",
    "df_eia_trans.date = pd.to_datetime(df_eia_trans.date, format='%Y-%m')\n",
    "\n",
    "# Load data from time frame\n",
    "df_eia_trans = df_eia_trans[(df_eia_trans.date > '2009-11-15') & (df_eia_trans.date < str(dt.now().date()))]\n",
    "\n",
    "# Resample for weekly data - starting on Friday\n",
    "df_eia_trans = df_eia_trans.set_index('date').resample('D').interpolate().asfreq('W-FRI')\n",
    "df_eia_trans = df_eia_trans.reset_index()\n",
    "\n",
    "# Merge data frames\n",
    "df = df.merge(df_eia_trans,how='outer').sort_values('date',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download non-oecd_cons and merge with df (MONTHLY)\n",
    "url_trans = url_eia + 'STEO.PATC_NON_OECD.M'\n",
    "label = 'non-oecd_cons'\n",
    "\n",
    "# Get request from URL, convert to json\n",
    "r = requests.get(url_trans)\n",
    "json_trans = r.json()\n",
    "\n",
    "# Load json data and convert date to YYYY-MM-DD, then to datetime\n",
    "df_eia_trans = pd.DataFrame(list(json_trans['series'][0]['data']),columns=['date',label])\n",
    "df_eia_trans.date = df_eia_trans.date + '01'\n",
    "df_eia_trans.date = pd.to_datetime(df_eia_trans.date, format='%Y-%m')\n",
    "\n",
    "# Load data from time frame\n",
    "df_eia_trans = df_eia_trans[(df_eia_trans.date > '2009-11-15') & (df_eia_trans.date < str(dt.now().date()))]\n",
    "\n",
    "# Resample for weekly data - starting on Friday\n",
    "df_eia_trans = df_eia_trans.set_index('date').resample('D').interpolate().asfreq('W-FRI')\n",
    "df_eia_trans = df_eia_trans.reset_index()\n",
    "\n",
    "# Merge data frames\n",
    "df = df.merge(df_eia_trans,how='outer').sort_values('date',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add world_cons (non-oecd_cons + oecd_cons)\n",
    "df['world_cons'] = df['non-oecd_cons'] + df['oecd_cons']\n",
    "\n",
    "# Sort data by date ascending\n",
    "df = df.sort_values(by=['date'],ascending=True)\n",
    "\n",
    "df = df[(df.date >= '2010-01-01') & (df.date <= dt.now().date().strftime('%Y-%m')+'-01')]\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save df_dropped to csv\n",
    "df.to_csv(data_interim_dir+'eia_data_weekly.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
